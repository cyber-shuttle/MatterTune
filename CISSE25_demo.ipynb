{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46887664-4eb5-4757-b2da-1a686fedb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: airavata-python-sdk[notebook] in /opt/conda/lib/python3.11/site-packages (2.0.16)\n",
      "Requirement already satisfied: oauthlib in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (3.2.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.0.0)\n",
      "Requirement already satisfied: thrift in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (0.21.0)\n",
      "Requirement already satisfied: thrift_connector in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (0.24)\n",
      "Requirement already satisfied: paramiko in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (3.5.1)\n",
      "Requirement already satisfied: scp in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (0.15.0)\n",
      "Requirement already satisfied: pysftp in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (0.2.9)\n",
      "Requirement already satisfied: configparser in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (7.2.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.0.7)\n",
      "Requirement already satisfied: pyjwt in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.8.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.11.4)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (14.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (2.2.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (6.0.1)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (8.1.6)\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.11/site-packages (from airavata-python-sdk[notebook]) (8.16.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (5.11.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython->airavata-python-sdk[notebook]) (4.8.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->airavata-python-sdk[notebook]) (0.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->airavata-python-sdk[notebook]) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /opt/conda/lib/python3.11/site-packages (from ipywidgets->airavata-python-sdk[notebook]) (3.0.14)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas->airavata-python-sdk[notebook]) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->airavata-python-sdk[notebook]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->airavata-python-sdk[notebook]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->airavata-python-sdk[notebook]) (2025.2)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.11/site-packages (from paramiko->airavata-python-sdk[notebook]) (4.3.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.11/site-packages (from paramiko->airavata-python-sdk[notebook]) (41.0.4)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.11/site-packages (from paramiko->airavata-python-sdk[notebook]) (1.5.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->airavata-python-sdk[notebook]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->airavata-python-sdk[notebook]) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->airavata-python-sdk[notebook]) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->airavata-python-sdk[notebook]) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->airavata-python-sdk[notebook]) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->airavata-python-sdk[notebook]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->airavata-python-sdk[notebook]) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->airavata-python-sdk[notebook]) (3.0.0)\n",
      "Requirement already satisfied: six>=1.7.2 in /opt/conda/lib/python3.11/site-packages (from thrift->airavata-python-sdk[notebook]) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.3->paramiko->airavata-python-sdk[notebook]) (1.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython->airavata-python-sdk[notebook]) (0.8.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->airavata-python-sdk[notebook]) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython->airavata-python-sdk[notebook]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->airavata-python-sdk[notebook]) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->airavata-python-sdk[notebook]) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->airavata-python-sdk[notebook]) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython->airavata-python-sdk[notebook]) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko->airavata-python-sdk[notebook]) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: ipywidgets in /opt/conda/lib/python3.11/site-packages (8.1.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U \"airavata-python-sdk[notebook]\"\n",
    "%pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5edc1b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded airavata_jupyter_magic (2.0.16) \n",
      "(current runtime = local)\n",
      "\n",
      "  %authenticate                              -- Authenticate to access high-performance runtimes.\n",
      "  %request_runtime <rt> [args]               -- Request a runtime named <rt> with configuration <args>.\n",
      "                                                Call multiple times to request multiple runtimes.\n",
      "  %restart_runtime <rt>                      -- Restart runtime <rt> if it hangs. This will clear all variables.\n",
      "  %stop_runtime <rt>                         -- Stop runtime <rt> when no longer needed.\n",
      "  %wait_for_runtime <rt>                     -- Wait for runtime <rt> to be ready.\n",
      "  %switch_runtime <rt>                       -- Switch the active runtime to <rt>. All subsequent cells will run here.\n",
      "  %%run_on <rt>                              -- Force a cell to always execute on <rt>, regardless of the active runtime.\n",
      "  %stat_runtime <rt>                         -- Show the status of runtime <rt>.\n",
      "  %copy_data source=<r1:f1> target=<r2:f2>   -- Copy <f1> in <r1> to <f2> in <r2>.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Authenticated.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Authenticated.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting runtime=hpc_gpu...\n",
      "[NeuroData25VC2:cloud, 60 Minutes, 1 Node(s), 1 CPU(s), 0 GPU(s), 16000 MB RAM, 1024 MB VRAM]\n",
      "* modules=[]\n",
      "* libraries=['python=3.10', 'pip', 'pytorch', 'pytorch-lightning', 'ase', 'scikit-learn', 'torchmetrics', 'numpy', 'wandb', 'tensorboard', 'tensorboardX', 'tqdm', 'rich', 'mattersim', 'fairchem-core']\n",
      "* pip=['git+https://github.com/cyber-shuttle/mattertune.git']\n",
      "* mounts=[]\n",
      "Requested runtime=hpc_gpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to runtime=hpc_gpu.\n"
     ]
    }
   ],
   "source": [
    "import airavata_jupyter_magic\n",
    "\n",
    "%authenticate\n",
    "%request_runtime hpc_gpu --file=cybershuttle.yml --walltime=60 --use=NeuroData25VC2:cloud\n",
    "%wait_for_runtime hpc_gpu\n",
    "%switch_runtime hpc_gpu\n",
    "# %copy_data -f source=local:examples/water-thermodynamics/data.zip target=hpc_gpu:data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15682514-4c7d-4caf-a414-682f36ef5d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[32m⠸\u001b[0m Connecting to=hpc_gpu... status=CONNECTED\n",
      "\u001b[1A\u001b[2KSat May  3 23:13:43 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  GRID A100X-10C                 On  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   N/A    P0              N/A /  N/A |   6156MiB / 10240MiB |     77%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2126      C   ...le/scratch/envs/b61781ba/bin/python      437MiB |\n",
      "|    0   N/A  N/A      2297      C   ...le/scratch/envs/b61781ba/bin/python      437MiB |\n",
      "|    0   N/A  N/A      3086      C   ...le/scratch/envs/641aaa5d/bin/python     5279MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32b320-cc89-4f95-9d1c-bff7b4c14dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/cyber-shuttle/MatterTune/refs/heads/main/examples/water-thermodynamics/data/train_water_1000_eVAng.xyz -O train_water_1000_eVAng.xyz\n",
    "! wget https://raw.githubusercontent.com/cyber-shuttle/MatterTune/refs/heads/main/examples/water-thermodynamics/data/val_water_1000_eVAng.xyz -O val_water_1000_eVAng.xyz\n",
    "! wget https://raw.githubusercontent.com/cyber-shuttle/MatterTune/refs/heads/main/examples/water-thermodynamics/data/H2O.xyz -O H2O.xyz\n",
    "! wget https://raw.githubusercontent.com/cyber-shuttle/MatterTune/refs/heads/main/examples/water-thermodynamics/data/water_1000_eVAng-energy_reference.json -O water_1000_eVAng-energy_reference.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import rich\n",
    "import nshutils as nu\n",
    "\n",
    "from ase.io import read\n",
    "from ase import Atoms\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mattertune.configs as MC\n",
    "from mattertune import MatterTuner\n",
    "from mattertune.backbones import (\n",
    "    MatterSimM3GNetBackboneModule,\n",
    "    JMPBackboneModule,\n",
    "    ORBBackboneModule,\n",
    "    EqV2BackboneModule,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(args_dict: dict):\n",
    "    \"\"\"\n",
    "    Fine-tune a Pre-trained Atomistic Foundation Model using MatterTuner.\n",
    "    - args_dict: Dictionary containing hyperparameters and configurations for fine-tuning.\n",
    "    \"\"\"\n",
    "    def hparams():\n",
    "        hparams = MC.MatterTunerConfig.draft()\n",
    "        \n",
    "        ## Choose Backbone Model type\n",
    "        if args_dict[\"model_type\"] == \"mattersim-1m\":\n",
    "            hparams.model = MC.MatterSimBackboneConfig.draft()\n",
    "            hparams.model.graph_convertor = MC.MatterSimGraphConvertorConfig.draft()\n",
    "            hparams.model.pretrained_model = \"MatterSim-v1.0.0-1M\"\n",
    "        elif args_dict[\"model_type\"] == \"jmp-s\":\n",
    "            hparams.model = MC.JMPBackboneConfig.draft()\n",
    "            hparams.model.graph_computer = MC.JMPGraphComputerConfig.draft()\n",
    "            hparams.model.graph_computer.pbc = True\n",
    "            hparams.model.pretrained_model = \"jmp-s\"\n",
    "        elif \"orb\" in args_dict[\"model_type\"]:\n",
    "            hparams.model = MC.ORBBackboneConfig.draft()\n",
    "            hparams.model.pretrained_model = args_dict[\"model_type\"]\n",
    "        elif args_dict[\"model_type\"] == \"eqv2\":\n",
    "            hparams.model = MC.EqV2BackboneConfig.draft()\n",
    "            hparams.model.checkpoint_path = Path(\n",
    "                \"/net/csefiles/coc-fung-cluster/nima/shared/checkpoints/eqV2_31M_mp.pt\"\n",
    "            )\n",
    "            hparams.model.atoms_to_graph = MC.FAIRChemAtomsToGraphSystemConfig.draft()\n",
    "            hparams.model.atoms_to_graph.radius = 8.0\n",
    "            hparams.model.atoms_to_graph.max_num_neighbors = 20\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid model type, please choose from ['mattersim-1m', 'jmp-s', 'orb-v2']\"\n",
    "            )\n",
    "        hparams.model.reset_output_heads = True\n",
    "        \n",
    "        ## Set Hyperparameters of optimizer and scheduler\n",
    "        hparams.model.optimizer = MC.AdamWConfig(\n",
    "            lr=args_dict[\"lr\"],\n",
    "            amsgrad=False,\n",
    "            betas=(0.9, 0.95),\n",
    "            eps=1.0e-8,\n",
    "            weight_decay=0.1,\n",
    "        )\n",
    "        hparams.model.lr_scheduler = MC.ReduceOnPlateauConfig(\n",
    "            mode=\"min\",\n",
    "            monitor=f\"val/forces_mae\",\n",
    "            factor=0.8,\n",
    "            patience=5,\n",
    "            min_lr=1e-8,\n",
    "        )\n",
    "        hparams.trainer.ema = MC.EMAConfig(decay=0.99)\n",
    "\n",
    "        # Add model properties, these are the properties to be predicted by the model\n",
    "        hparams.model.properties = []\n",
    "        energy_coefficient = 1.0 \n",
    "        conservative = args_dict[\"conservative\"] or \"mattersim\" in args_dict[\"model_type\"]\n",
    "        energy = MC.EnergyPropertyConfig(\n",
    "            loss=MC.MSELossConfig(), loss_coefficient=energy_coefficient\n",
    "        )\n",
    "        hparams.model.properties.append(energy)\n",
    "        forces = MC.ForcesPropertyConfig(\n",
    "            loss=MC.MSELossConfig(), conservative=conservative, loss_coefficient=1.0\n",
    "        )\n",
    "        hparams.model.properties.append(forces)\n",
    "\n",
    "        ## Set Data Module to load the dataset\n",
    "        ## Here we downsampled 30 data points from the original training set because it's already enough\n",
    "        hparams.data = MC.ManualSplitDataModuleConfig.draft()\n",
    "        hparams.data.train = MC.XYZDatasetConfig.draft()\n",
    "        hparams.data.train.src = \"./train_water_1000_eVAng.xyz\"\n",
    "        hparams.data.train.down_sample = 30\n",
    "        hparams.data.train.down_sample_refill = True ### Although we only used 30 samples, we repeate them to reach the original dataset size\n",
    "        hparams.data.validation = MC.XYZDatasetConfig.draft()\n",
    "        hparams.data.validation.src = \"./val_water_1000_eVAng.xyz\"\n",
    "        hparams.data.batch_size = args_dict[\"batch_size\"]\n",
    "\n",
    "        ## Normalization usually helps with training stability and convergence\n",
    "        ## Here we normalize the energy firstly by linear referencing and then divide by number of atoms\n",
    "        hparams.model.normalizers = {\n",
    "            \"energy\": [\n",
    "                MC.PerAtomReferencingNormalizerConfig(\n",
    "                    per_atom_references=Path(\"./water_1000_eVAng-energy_reference.json\")\n",
    "                ),\n",
    "                MC.PerAtomNormalizerConfig(),\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        ## Trainer Hyperparameters, used to configure number of epochs, devices, etc.\n",
    "        hparams.trainer = MC.TrainerConfig.draft()\n",
    "        hparams.trainer.max_epochs = args_dict[\"max_epochs\"]\n",
    "        hparams.trainer.accelerator = \"gpu\"\n",
    "        hparams.trainer.devices = args_dict[\"devices\"]\n",
    "        hparams.trainer.gradient_clip_algorithm = \"norm\"\n",
    "        hparams.trainer.gradient_clip_val = 1.0\n",
    "        hparams.trainer.precision = \"32\"\n",
    "\n",
    "        ## Configure Early Stopping\n",
    "        hparams.trainer.early_stopping = MC.EarlyStoppingConfig(\n",
    "            monitor=f\"val/forces_mae\", patience=50, mode=\"min\"\n",
    "        )\n",
    "\n",
    "        ## Configure Model Checkpoint\n",
    "        hparams.trainer.checkpoint = MC.ModelCheckpointConfig(\n",
    "            monitor=\"val/forces_mae\",\n",
    "            dirpath=\"./checkpoints\",\n",
    "            filename=f\"{args_dict['model_type']}-best\",\n",
    "            save_top_k=1,\n",
    "            mode=\"min\",\n",
    "        )\n",
    "\n",
    "        ## Configure Logger\n",
    "        hparams.trainer.loggers = [\n",
    "            MC.TensorBoardLoggerConfig(\n",
    "                save_dir=\"./logs\",\n",
    "                name=f\"{args_dict['model_type']}-tune\",\n",
    "                version=0,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        ## Additional trainer settings\n",
    "        ## Here since mattersim models are conservative, we set inference_mode to False to enable differentiable energy prediction\n",
    "        hparams.trainer.additional_trainer_kwargs = {\n",
    "            \"inference_mode\": False,\n",
    "        }\n",
    "\n",
    "        hparams = hparams.finalize(strict=False)\n",
    "        return hparams\n",
    "\n",
    "    mt_config = hparams()\n",
    "    model, trainer = MatterTuner(mt_config).tune()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b89186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(args_dict: dict):\n",
    "    \"\"\"\n",
    "    Perform inference using the fine-tuned model on the validation dataset.\n",
    "    Load the fine-tuned model from the checkpoint using .load_from_checkpoint function.\n",
    "    Convert the loaded model to an ASE calculator using the `ase_calculator` method.\n",
    "    Evaluate the model on the validation dataset and compute the MAE for energies and forces.\n",
    "    \"\"\"\n",
    "\n",
    "    ckpt_path = f\"./checkpoints/{args_dict['model_type']}-best.ckpt\"\n",
    "    if \"mattersim\" in args_dict[\"model_type\"]:\n",
    "        ft_model = MatterSimM3GNetBackboneModule.load_from_checkpoint(ckpt_path)\n",
    "    elif \"jmp\" in args_dict[\"model_type\"]:\n",
    "        ft_model = JMPBackboneModule.load_from_checkpoint(ckpt_path)\n",
    "    elif \"orb\" in args_dict[\"model_type\"]:\n",
    "        ft_model = ORBBackboneModule.load_from_checkpoint(ckpt_path)\n",
    "    elif \"eqv2\" in args_dict[\"model_type\"]:\n",
    "        ft_model = EqV2BackboneModule.load_from_checkpoint(ckpt_path)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid model type, please choose from ['mattersim-1m', 'jmp-s', 'orb-v2', 'eqv2']\"\n",
    "        )\n",
    "    \n",
    "    val_atoms_list:list[Atoms] = read(\"./val_water_1000_eVAng.xyz\", \":\") # type: ignore\n",
    "    calc = ft_model.ase_calculator(\n",
    "        device = f\"cuda:{args_dict['devices'][0]}\"\n",
    "    )\n",
    "    energies_per_atom = []\n",
    "    forces = []\n",
    "    pred_energies_per_atom = []\n",
    "    pred_forces = []\n",
    "    for atoms in tqdm(val_atoms_list):\n",
    "        energies_per_atom.append(atoms.get_potential_energy() / len(atoms))\n",
    "        forces.extend(np.array(atoms.get_forces()).tolist())\n",
    "        atoms.set_calculator(calc)\n",
    "        pred_energies_per_atom.append(atoms.get_potential_energy() / len(atoms))\n",
    "        pred_forces.extend(np.array(atoms.get_forces()).tolist())\n",
    "        \n",
    "    e_mae = torch.nn.L1Loss()(torch.tensor(energies_per_atom), torch.tensor(pred_energies_per_atom))\n",
    "    f_mae = torch.nn.L1Loss()(torch.tensor(forces), torch.tensor(pred_forces))\n",
    "    \n",
    "    rich.print(f\"Energy MAE: {e_mae} eV/atom\")\n",
    "    rich.print(f\"Forces MAE: {f_mae} eV/Ang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73862e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We support various logging methods, including TensorBoard, WandB, and CSV files. \n",
    "## In this demo we used TensorBoard, so we can visualize the training process using TensorBoard.\n",
    "## Below is a scripts to visualize the training loss using TensorBoard logs.\n",
    "\n",
    "def visualize_tensorboard_logs(metric_name: str, unit: str):\n",
    "    from tensorboard.backend.event_processing import event_accumulator\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 读取事件文件\n",
    "    ea = event_accumulator.EventAccumulator(\"./logs/mattersim-1m-tune/version_1\")\n",
    "    ea.Reload()\n",
    "\n",
    "    # 查看有哪些 scalar 标签\n",
    "    print(ea.Tags()[\"scalars\"])\n",
    "\n",
    "    # 比如我们导出 'loss' 的曲线\n",
    "    scalar_events = ea.Scalars(metric_name)\n",
    "    steps = [e.step for e in scalar_events]\n",
    "    values = [e.value for e in scalar_events]\n",
    "\n",
    "    # 绘图\n",
    "    plt.plot(steps, values)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.title(f\"{metric_name} ({unit}) over steps\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b02ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"model_type\": \"mattersim-1m\",\n",
    "    \"conservative\": True,\n",
    "    \"batch_size\": 2,\n",
    "    \"max_epochs\": 5,\n",
    "    \"lr\": 8e-5,\n",
    "    \"devices\": [0],\n",
    "}\n",
    "fine_tune(args_dict=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89cf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tensorboard_logs(\"val/forces_mae\", unit=\"eV/Ang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(args_dict=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Further we can use the fine-tuned model to run Molecular Dynamics (MD) simulations.\n",
    "from ase.md.langevin import Langevin\n",
    "import ase.units as units\n",
    "\n",
    "\n",
    "atoms:Atoms = read(\"./H2O.xyz\")  # type: ignore\n",
    "atoms.pbc = True\n",
    "ft_model = MatterSimM3GNetBackboneModule.load_from_checkpoint(\"./checkpoints/mattersim-1m-best.ckpt\")\n",
    "calc = ft_model.ase_calculator()\n",
    "atoms.calc = calc\n",
    "\n",
    "dyn = Langevin(\n",
    "    atoms,\n",
    "    temperature_K=600,\n",
    "    timestep=0.5 * units.fs,\n",
    "    friction=0.02,\n",
    ")\n",
    "pbar = tqdm(total=1000, desc=\"MD Simulation Steps\")\n",
    "for step in range(1000):\n",
    "    dyn.step()\n",
    "    temp = atoms.get_temperature()\n",
    "    pbar.set_description(f\"MD Simulation Steps (Temperature: {temp:.2f} K/{600:.2f} K)\")\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9869904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
